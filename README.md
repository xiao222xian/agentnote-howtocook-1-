1. 环境配置
拉取代码---安装环境---配置kimi api
2. 数据准备
~数据准备模块的核心是实现"小块检索，大块生成"的父子文本块架构。
~整体流程：初始化模块（传入数据路径）→ 调用load_documents（加载文件→生成父文档→自动提取元数据）→ 调用chunk_documents（结构化分块→生成子块→建立父子关联）→ 为上层模块提供（父文档/子块/元数据/统计信息）
~父子文本块映射关系：
父文档（完整菜谱）
├── 子块1：菜品介绍 + 难度评级
├── 子块2：必备原料和工具
├── 子块3：计算（用量配比）
├── 子块4：操作（制作步骤）
└── 子块5：附加内容（变化做法）
~基本流程：
- 检索阶段：使用小的子块进行精确匹配，提高检索准确性
- 生成阶段：传递完整的父文档给LLM，确保上下文完整性
- 智能去重：当检索到同一道菜的多个子块时，合并为一个完整菜谱
~元数据增强：
- 菜品分类：从文件路径推断（荤菜、素菜、汤品等）
- 难度等级：从内容中的星级标记提取
- 菜品名称：从文件名提取
- 文档关系：建立父子文档的ID映射关系
~以"西红柿炒鸡蛋"为例，分块后的效果：
原文档：西红柿炒鸡蛋的做法.md (父文档)
├── 子块1：# 西红柿炒鸡蛋的做法 + 简介 + 难度评级
├── 子块2：## 必备原料和工具 + 食材清单
├── 子块3：## 计算 + 用量配比公式
├── 子块4：## 操作 + 详细制作步骤
└── 子块5：## 附加内容

3. 索引检索IndexConstructionModule
1 核心设计
1.1 索引构建
索引构建模块的核心任务是将文本块转换为向量表示，并构建高效的检索索引。这里选择之前一直使用的BGE-small-zh-v1.5作为嵌入模型，并使用FAISS作为向量数据库来存储和检索向量。为了提升系统启动速度，实现索引缓存机制。首次构建后会将FAISS索引保存到本地，后续启动时直接加载已有索引，可以将启动时间从几分钟缩短到几秒钟。是实现「向量检索（理解语义、匹配意图）」的关键环节
1.2 混合检索
检索优化模块实现了多种检索策略的组合。采用双路检索的方式：向量检索基于语义相似度，擅长理解查询意图；BM25检索基于关键词匹配，擅长精确匹配。为了综合两种检索方式的优势，我们使用RRF（Reciprocal Rank Fusion）算法来融合检索结果。这个算法会综合考虑两种检索结果的排名信息，避免过度依赖单一检索方式。
2 索引构建模块
初始化配置 → 加载嵌入模型 → 优先加载本地索引 → 提供检索能力
初始化模块：指定嵌入模型（默认 BAAI/bge-small-zh-v1.5）和索引本地保存路径（默认./vector_index）；
自动加载嵌入模型：完成文本→语义向量的编码工具初始化，为后续向量化做准备；
上层模块调用 load_index：优先尝试加载本地已保存的向量索引；
  - 加载成功：直接获取 FAISS 向量存储对象（vectorstore），具备语义相似度检索能力；
  - 加载失败 / 索引路径不存在：调用 build_vector_index，传入数据准备模块生成的结构化子块文档，通过嵌入模型编码为向量并构建新 FAISS 索引，构建完成后调用 save_index 保存到本地指定路径，最终获得 vectorstore 并提供检索能力。
核心本质：通过 “预加载嵌入模型 + 优先复用本地索引”，高效构建 / 复用向量索引，为 RAG 系统提供 “理解语义” 的核心检索支撑。

4. 检索优化模块
该模块是 RAG 系统检索精度的核心优化层，类名为RetrievalOptimizationModule，核心职责是整合向量语义检索和BM25 关键词检索的优势，通过RRF 算法重排实现混合检索，并支持元数据精准过滤，解决单一检索的局限性，为生成模块提供更精准、更贴合用户意图的菜谱子块文档，是连接索引构建模块和生成集成模块的关键桥梁。
模块基于 LangChain 生态开发，实现了「双检索器初始化、混合检索 + RRF 重排、元数据过滤检索」三大核心能力。
初始化模块（注入FAISS向量库+子块文档）→ 自动设置向量/BM25双检索器 → 对外提供检索能力
├─ 基础检索需求 → 调用hybrid_search（双检索→RRF重排→返回顶k结果）；
└─ 带条件检索需求 → 调用metadata_filtered_search（混合检索扩大候选→元数据精准过滤→返回顶k结果）。
This content is only supported in a Feishu Docs
RRF 算法核心原理
核心思想：文档在单个检索结果中的排名越靠前，其最终融合分数越高，通过倒数排名的方式，将两个独立的检索排名融合为一个综合排名，避免单一检索的偏见。
核心公式：单个检索结果中，某文档的 RRF 分数 = 1/(k+rank)

5. 生成集成与系统整合模块
核心职责是集成大语言模型（LLM），基于检索优化模块返回的高相关性菜谱文档，结合定制化提示词（Prompt）和LangChain 表达式语言（LCEL），为用户生成贴合查询意图、格式规范、实用性强的烹饪相关回答，同时提供查询重写、查询路由、流式输出等增强能力，是连接检索结果和用户最终体验的核心模块。
模块基于LangChain 生态+月之暗面（Moonshot）Kimi 大模型开发，实现了「LLM 初始化、多类型回答生成、智能查询处理、流式输出」四大核心能力

~生成集成模块是整个RAG系统的"大脑"，负责理解用户意图、路由查询类型，并生成高质量的回答。
设计思路
智能查询路由：根据用户查询自动判断是列表查询、详细查询还是一般查询，选择最适合的生成策略。
查询重写优化：对模糊不清的查询进行智能重写，提升检索效果。比如将"做菜"重写为"简单易做的家常菜谱"。
多模式生成：
- 列表模式：适用于推荐类查询，返回简洁的菜品列表
- 详细模式：适用于制作类查询，提供分步骤的详细指导
- 基础模式：适用于一般性问题，提供常规回答

~系统整合模块主程序负责协调各个模块，实现完整的RAG流程：数据准备 → 索引构建 → 检索优化 → 生成集成。同时提供了索引缓存、交互式问答等实用功能。

主系统类设计---系统初始化流程（初始化数据准备模块、索引构建模块、生成集成模块）---知识库构建流程---智能问答流程（智能路由 → 查询优化 → 混合检索 → 父子文档处理 → 多模式生成list、detail、basic）-交互式问答




